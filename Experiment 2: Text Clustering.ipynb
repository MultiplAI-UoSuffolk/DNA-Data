{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_20newsgroups # importing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluations = []\n",
    "# evaluations_std = []\n",
    "\n",
    "\n",
    "# def fit_and_evaluate(km, X, name=None, n_runs=5):\n",
    "#     name = km.__class__.__name__ if name is None else name\n",
    "\n",
    "#     train_times = []\n",
    "#     scores = defaultdict(list)\n",
    "#     for seed in range(n_runs):\n",
    "#         km.set_params(random_state=seed)\n",
    "#         t0 = time()\n",
    "#         km.fit(X)\n",
    "#         train_times.append(time() - t0)\n",
    "#         scores[\"Homogeneity\"].append(metrics.homogeneity_score(labels, km.labels_))\n",
    "#         scores[\"Completeness\"].append(metrics.completeness_score(labels, km.labels_))\n",
    "#         scores[\"V-measure\"].append(metrics.v_measure_score(labels, km.labels_))\n",
    "#         scores[\"Adjusted Rand-Index\"].append(\n",
    "#             metrics.adjusted_rand_score(labels, km.labels_)\n",
    "#         )\n",
    "#         scores[\"Silhouette Coefficient\"].append(\n",
    "#             metrics.silhouette_score(X, km.labels_, sample_size=2000)\n",
    "#         )\n",
    "#     train_times = np.asarray(train_times)\n",
    "\n",
    "#     print(f\"clustering done in {train_times.mean():.2f} ± {train_times.std():.2f} s \")\n",
    "#     evaluation = {\n",
    "#         \"estimator\": name,\n",
    "#         \"train_time\": train_times.mean(),\n",
    "#     }\n",
    "#     evaluation_std = {\n",
    "#         \"estimator\": name,\n",
    "#         \"train_time\": train_times.std(),\n",
    "#     }\n",
    "#     for score_name, score_values in scores.items():\n",
    "#         mean_score, std_score = np.mean(score_values), np.std(score_values)\n",
    "#         print(f\"{score_name}: {mean_score:.3f} ± {std_score:.3f}\")\n",
    "#         evaluation[score_name] = mean_score\n",
    "#         evaluation_std[score_name] = std_score\n",
    "#     evaluations.append(evaluation)\n",
    "#     evaluations_std.append(evaluation_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names) # printing all the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3845 documents - 4 categories\n"
     ]
    }
   ],
   "source": [
    "# defining topics\n",
    "categories = [\n",
    "    \"comp.os.ms-windows.misc\",\n",
    "    \"comp.sys.mac.hardware\",\n",
    "    \"talk.politics.guns\",\n",
    "    \"sci.space\",\n",
    "]\n",
    "\n",
    "# taking away unwanted parts of the data this prevents classifiers overfitting on metadata \n",
    "dataset = fetch_20newsgroups(\n",
    "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
    "    subset=\"all\",\n",
    "    categories=categories,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# printing the number of documents and categories\n",
    "labels = dataset.target\n",
    "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
    "true_k = unique_labels.shape[0]\n",
    "\n",
    "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorization done in 0.381 s\n",
      "n_samples: 3845, n_features: 8397\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, # ignore terms that appear in more than 50% of docs\n",
    "    min_df=5, # ignore terms that arent in at least 5 docs\n",
    "    stop_words=\"english\", # this removes common english dialect words such as \"then, the, and etc\"\n",
    ")\n",
    "t0 = time() # records the time of vectorisation\n",
    "X_tfidf = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(f\"vectorization done in {time() - t0:.3f} s\")\n",
    "print(f\"n_samples: {X_tfidf.shape[0]}, n_features: {X_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidVectorizer uses an in-memory vocabulary to map most frequent words to features indices. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_features would contain the resulting number of unique terms after we used the parameters to cut down the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006\n"
     ]
    }
   ],
   "source": [
    "print(f\"{X_tfidf.nnz / np.prod(X_tfidf.shape):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above quantifys the sparsity of the X_tfidf matrix as the fraction of non-zero entries / total no. of elements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
